{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\users\\richa\\anaconda3\\lib\\site-packages (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.4.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (23.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.63.0rc2)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.38.4)\n",
      "Requirement already satisfied: namex in c:\\users\\richa\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\richa\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: rich in c:\\users\\richa\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\richa\\anaconda3\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in c:\\users\\richa\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\richa\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\richa\\anaconda3\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\richa\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\richa\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\richa\\anaconda3\\lib\\site-packages (from torch) (1.12.1rc1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\richa\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Richa\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer on CPU\n",
    "nlp = pipeline(\"fill-mask\", model=\"bert-base-uncased\", device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: research, Score: 0.5172\n",
      "Token: scientific, Score: 0.1693\n",
      "Token: related, Score: 0.0396\n",
      "Token: technical, Score: 0.0303\n",
      "Token: new, Score: 0.0184\n"
     ]
    }
   ],
   "source": [
    "result = nlp(\"Artificial intelligence is a [MASK] field.\")\n",
    "for res in result:\n",
    "    print(f\"Token: {res['token_str']}, Score: {res['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The capital of France is [MASK].\n",
      "Token: paris, Score: 0.4168\n",
      "Token: lille, Score: 0.0714\n",
      "Token: lyon, Score: 0.0634\n",
      "Token: marseille, Score: 0.0444\n",
      "Token: tours, Score: 0.0303\n",
      "\n",
      "\n",
      "Input: The quick brown fox jumps over the [MASK] dog.\n",
      "Token: little, Score: 0.1062\n",
      "Token: big, Score: 0.0696\n",
      "Token: small, Score: 0.0476\n",
      "Token: startled, Score: 0.0237\n",
      "Token: sleeping, Score: 0.0202\n",
      "\n",
      "\n",
      "Input: Machine learning is a [MASK] of artificial intelligence.\n",
      "Token: branch, Score: 0.6610\n",
      "Token: field, Score: 0.0812\n",
      "Token: form, Score: 0.0772\n",
      "Token: type, Score: 0.0273\n",
      "Token: subset, Score: 0.0234\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"The capital of France is [MASK].\",\n",
    "    \"The quick brown fox jumps over the [MASK] dog.\",\n",
    "    \"Machine learning is a [MASK] of artificial intelligence.\"\n",
    "]\n",
    "\n",
    "for sentence in inputs:\n",
    "    result = nlp(sentence)\n",
    "    print(f\"Input: {sentence}\")\n",
    "    for res in result:\n",
    "        print(f\"Token: {res['token_str']}, Score: {res['score']:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform inference and display results\n",
    "def perform_inference(nlp, sentence):\n",
    "    result = nlp(sentence)\n",
    "    print(f\"Input: {sentence}\")\n",
    "    for res in result:\n",
    "        print(f\"Token: {res['token_str']}, Score: {res['score']:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Inference Example:\n",
      "Input: Artificial intelligence is a [MASK] field.\n",
      "Token: research, Score: 0.5172\n",
      "Token: scientific, Score: 0.1693\n",
      "Token: related, Score: 0.0396\n",
      "Token: technical, Score: 0.0303\n",
      "Token: new, Score: 0.0184\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample inference with a single sentence\n",
    "print(\"Single Inference Example:\")\n",
    "perform_inference(nlp, \"Artificial intelligence is a [MASK] field.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Inference Examples:\n"
     ]
    }
   ],
   "source": [
    "print(\"Multiple Inference Examples:\")\n",
    "inputs = [\n",
    "    \"The capital of France is [MASK].\",\n",
    "    \"The quick brown fox jumps over the [MASK] dog.\",\n",
    "    \"Machine learning is a [MASK] of artificial intelligence.\",\n",
    "    \"Python is a popular [MASK] language.\",\n",
    "    \"The [MASK] is shining brightly today.\",\n",
    "    \"He is a [MASK] student in his class.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The capital of France is [MASK].\n",
      "Token: paris, Score: 0.4168\n",
      "Token: lille, Score: 0.0714\n",
      "Token: lyon, Score: 0.0634\n",
      "Token: marseille, Score: 0.0444\n",
      "Token: tours, Score: 0.0303\n",
      "\n",
      "\n",
      "Input: The quick brown fox jumps over the [MASK] dog.\n",
      "Token: little, Score: 0.1062\n",
      "Token: big, Score: 0.0696\n",
      "Token: small, Score: 0.0476\n",
      "Token: startled, Score: 0.0237\n",
      "Token: sleeping, Score: 0.0202\n",
      "\n",
      "\n",
      "Input: Machine learning is a [MASK] of artificial intelligence.\n",
      "Token: branch, Score: 0.6610\n",
      "Token: field, Score: 0.0812\n",
      "Token: form, Score: 0.0772\n",
      "Token: type, Score: 0.0273\n",
      "Token: subset, Score: 0.0234\n",
      "\n",
      "\n",
      "Input: Python is a popular [MASK] language.\n",
      "Token: programming, Score: 0.9610\n",
      "Token: python, Score: 0.0062\n",
      "Token: natural, Score: 0.0046\n",
      "Token: computer, Score: 0.0035\n",
      "Token: assembly, Score: 0.0014\n",
      "\n",
      "\n",
      "Input: The [MASK] is shining brightly today.\n",
      "Token: sun, Score: 0.7397\n",
      "Token: moon, Score: 0.0294\n",
      "Token: city, Score: 0.0230\n",
      "Token: sky, Score: 0.0224\n",
      "Token: school, Score: 0.0080\n",
      "\n",
      "\n",
      "Input: He is a [MASK] student in his class.\n",
      "Token: top, Score: 0.3139\n",
      "Token: popular, Score: 0.0731\n",
      "Token: good, Score: 0.0500\n",
      "Token: star, Score: 0.0389\n",
      "Token: favorite, Score: 0.0368\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in inputs:\n",
    "    perform_inference(nlp, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Inference Examples with More Context:\n"
     ]
    }
   ],
   "source": [
    "# Advanced inference examples with more context\n",
    "print(\"Advanced Inference Examples with More Context:\")\n",
    "advanced_inputs = [\n",
    "    \"The discovery of penicillin is considered a [MASK] in the field of medicine.\",\n",
    "    \"During the Renaissance, Leonardo da Vinci was known for his [MASK] inventions.\",\n",
    "    \"In the world of finance, the [MASK] market is closely watched by investors.\",\n",
    "    \"The theory of relativity was proposed by [MASK] Einstein.\",\n",
    "    \"Climate change is a [MASK] issue affecting the entire planet.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The discovery of penicillin is considered a [MASK] in the field of medicine.\n",
      "Token: milestone, Score: 0.5489\n",
      "Token: landmark, Score: 0.2753\n",
      "Token: breakthrough, Score: 0.1012\n",
      "Token: watershed, Score: 0.0142\n",
      "Token: first, Score: 0.0101\n",
      "\n",
      "\n",
      "Input: During the Renaissance, Leonardo da Vinci was known for his [MASK] inventions.\n",
      "Token: many, Score: 0.1264\n",
      "Token: mechanical, Score: 0.0965\n",
      "Token: technological, Score: 0.0743\n",
      "Token: numerous, Score: 0.0708\n",
      "Token: various, Score: 0.0657\n",
      "\n",
      "\n",
      "Input: In the world of finance, the [MASK] market is closely watched by investors.\n",
      "Token: stock, Score: 0.4562\n",
      "Token: capital, Score: 0.0581\n",
      "Token: financial, Score: 0.0500\n",
      "Token: money, Score: 0.0453\n",
      "Token: securities, Score: 0.0251\n",
      "\n",
      "\n",
      "Input: The theory of relativity was proposed by [MASK] Einstein.\n",
      "Token: albert, Score: 0.9958\n",
      "Token: karl, Score: 0.0006\n",
      "Token: carl, Score: 0.0003\n",
      "Token: george, Score: 0.0003\n",
      "Token: ernest, Score: 0.0003\n",
      "\n",
      "\n",
      "Input: Climate change is a [MASK] issue affecting the entire planet.\n",
      "Token: major, Score: 0.2853\n",
      "Token: global, Score: 0.2556\n",
      "Token: serious, Score: 0.0989\n",
      "Token: huge, Score: 0.0825\n",
      "Token: worldwide, Score: 0.0245\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in advanced_inputs:\n",
    "    perform_inference(nlp, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Examples with Longer Texts:\n"
     ]
    }
   ],
   "source": [
    "# Test the model with longer texts\n",
    "print(\"Inference Examples with Longer Texts:\")\n",
    "long_texts = [\n",
    "    \"In computer science, artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. AI research has been defined as the study of any device that perceives its environment and takes actions that maximize its chance of successfully achieving its [MASK].\",\n",
    "    \"The quick brown fox jumps over the lazy dog. This sentence is often used to test the [MASK] of typewriters and computer keyboards.\",\n",
    "    \"The history of machine learning dates back to the early days of AI research. Machine learning is a subfield of AI focused on the development of algorithms that allow computers to learn from and make predictions or decisions based on [MASK].\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: In computer science, artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. AI research has been defined as the study of any device that perceives its environment and takes actions that maximize its chance of successfully achieving its [MASK].\n",
      "Token: goal, Score: 0.6425\n",
      "Token: goals, Score: 0.2578\n",
      "Token: objectives, Score: 0.0264\n",
      "Token: purpose, Score: 0.0190\n",
      "Token: mission, Score: 0.0102\n",
      "\n",
      "\n",
      "Input: The quick brown fox jumps over the lazy dog. This sentence is often used to test the [MASK] of typewriters and computer keyboards.\n",
      "Token: performance, Score: 0.2052\n",
      "Token: functionality, Score: 0.0539\n",
      "Token: accuracy, Score: 0.0504\n",
      "Token: design, Score: 0.0443\n",
      "Token: speed, Score: 0.0433\n",
      "\n",
      "\n",
      "Input: The history of machine learning dates back to the early days of AI research. Machine learning is a subfield of AI focused on the development of algorithms that allow computers to learn from and make predictions or decisions based on [MASK].\n",
      "Token: them, Score: 0.3928\n",
      "Token: algorithms, Score: 0.0505\n",
      "Token: mathematics, Score: 0.0211\n",
      "Token: knowledge, Score: 0.0209\n",
      "Token: models, Score: 0.0177\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in long_texts:\n",
    "    perform_inference(nlp, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Examples with Technical Terminology:\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference Examples with Technical Terminology:\")\n",
    "technical_inputs = [\n",
    "    \"The Large Hadron Collider (LHC) is the world's largest and most powerful [MASK] accelerator.\",\n",
    "    \"Quantum computing is an area of computing focused on developing computer technology based on the principles of [MASK] mechanics.\",\n",
    "    \"In neural networks, the activation function of a neuron defines the output of that neuron given a set of [MASK].\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The Large Hadron Collider (LHC) is the world's largest and most powerful [MASK] accelerator.\n",
      "Token: particle, Score: 0.9606\n",
      "Token: linear, Score: 0.0352\n",
      "Token: ion, Score: 0.0007\n",
      "Token: electron, Score: 0.0005\n",
      "Token: atom, Score: 0.0002\n",
      "\n",
      "\n",
      "Input: Quantum computing is an area of computing focused on developing computer technology based on the principles of [MASK] mechanics.\n",
      "Token: quantum, Score: 0.9989\n",
      "Token: classical, Score: 0.0007\n",
      "Token: statistical, Score: 0.0002\n",
      "Token: continuum, Score: 0.0001\n",
      "Token: wave, Score: 0.0000\n",
      "\n",
      "\n",
      "Input: In neural networks, the activation function of a neuron defines the output of that neuron given a set of [MASK].\n",
      "Token: inputs, Score: 0.6353\n",
      "Token: conditions, Score: 0.0767\n",
      "Token: parameters, Score: 0.0545\n",
      "Token: stimuli, Score: 0.0342\n",
      "Token: states, Score: 0.0205\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in technical_inputs:\n",
    "    perform_inference(nlp, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All inferences completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Final summary printout\n",
    "print(\"All inferences completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
